{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tweets\n",
    "\n",
    "## Objective and method\n",
    "The purpose for this notebook is to query Twitter using a pre defined list of search terms and to transform tweets returned by these criteria into a pandas dataframe, with one row corresponding to one tweet. The resulting dataframe will then be saved as a 'csv file which can then be analysed in downstream processes.\n",
    "\n",
    "This notebook was run twice weekly due to download constraints imposed by Twitter. On day 1 we would run a subset of search terms and on day 2 the remainder. We create a different output file for each run and the following process, 1_7 Clean and Analyse Tweets, loads and concatenates all these files to create a consolidated body of tweets.\n",
    "\n",
    "## Other information\n",
    "\n",
    "### Tools\n",
    "We set up a Twitter developer account and attempted to use the Tweepy tool to extract tweets. Our method was influenced by \n",
    "https://www.earthdatascience.org/courses/use-data-open-source-python/intro-to-apis/twitter-data-in-python/\n",
    "\n",
    "These tools were mostly effective when extracting data up to one week old but we encountered problems trying to access historic data. We also had a number of timeout issues where the Twitter host rejected our connection once we had exceeded call thresholds available to users of the standard Twitter API account.\n",
    "\n",
    "### Problems encountered\n",
    "\n",
    "Unfortunately, the Twitter API only returns tweets from the most recent week, irrespective of which start date one provides. This means that we will have to run the extract on a weekly basis (to get the prior week's tweets) in order to get a reasonable body of tweets. This is suboptimal restricted our ability to go back and query prior results, particularly results around the time when the Mayor published GLA evidence into the causes of crime and also during the runup period to the Mayoral elections. This was a considerable issue for the project because the topic received far more media and online attention during those times and so the associated body of tweets would have provided useful material for our project.\n",
    "\n",
    "I addition, running search queries on Twitter is very time consuming and prone to being timed out when user thresholds are exceeded. For example, see Appendix A for messages received when I timed out searching Twitter using the search term \"sadiq AND khan\". When it does successfully conclude, running this search term takes between 3-5 hours in duration to complete and returns in the region of 10,000 tweets. However, this search consistently fails due to timeouts and this is a consideration for other researchers interested in using Twitter developer accounts to analyse Twitter data, something we discuss further below. \n",
    "- While we did have a number of successful runs with the search terms = 'sadiq khan', the final two attempted runs on 26/08/2021 and 30/08/2021 failed with the same timeout related error (see Appendix C)\n",
    "\n",
    "### Twitter research account\n",
    "We applied to Twitter's Academic Research track https://developer.twitter.com/en/products/twitter-api/academic-research because this allows researchers to access historic tweets, and in higher tweet volumes. Our requests were rejected however and we discuss this in further detail in Appendix B. The reason we discuss this is because researching Twitter data without academic access is difficult and yet getting academic access whilst not having a presence on University websites does not seem possible.\n",
    "\n",
    "### Tweepy Code References:\n",
    "Our Twitter code was informed by a number of online sources and we detail their use below:\n",
    "- retweet and favourite counts, better dataframe creator using Tweepy - https://towardsdatascience.com/how-to-build-a-dataset-from-twitter-using-python-tweepy-861bdbc16fa5\n",
    "- Getting user and location - https://stackoverflow.com/questions/50366489/how-to-get-twitter-users-screen-name-or-userid-from-a-specific-geolocations\n",
    "- Cleaning tweet text and finding out if retweet - https://stackoverflow.com/questions/50052330/tweepy-check-if-a-tweet-is-a-retweet\n",
    "- geocordinates - https://stackoverflow.com/questions/46044445/not-able-to-scrape-geo-coordinate-with-tweets-lat-lon\n",
    "- avoiding twitter api rate limit - https://stackoverflow.com/questions/21308762/avoid-twitter-api-limitation-with-tweepy\n",
    "- keeping authentication details secret - https://www.digitalocean.com/community/tutorials/how-to-create-a-twitterbot-with-python-3-and-the-tweepy-library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Twitter Data\n",
    "We have two choices to loading twitter data:\n",
    "- 1.1. use the Tweepy API (but this can take hours)\n",
    "- 1.2. load the previously saved Twitter data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data from Twitter \n",
    "#### 1.1.1 Twitter credentials file\n",
    "I don't want to make my Twitter credentials public and so these are loaded from a credentials file and that file is not uploaded to github. \n",
    "\n",
    "To replicate this code, create a 'credentials.py' file with the following lines (using your own credential details):\n",
    "\n",
    "`\n",
    "consumer_key = 'your_consumer_key'\n",
    "consumer_secret = 'your_consumer_secret'\n",
    "access_token = 'your_access_token'\n",
    "access_token_secret = 'your_access_token_secret'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from credentials import *\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1.1.2 Set date parameters\n",
    "Using search words, I wanted to get all tweets since a start date of July 1, 2019, which was just prior to the Mayor publishing evidence into the causes of serious violent crime. However, while we still include the start date in the code, <b>Twitter API limitations mean we can only get Twitter data for the prior week and so the start_date parameter is redundant</b>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./DataSources/TwitterData/raw_tweets_20210831.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(datetime.date(2019, 7, 1), '20210831')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_from = datetime.date(2019, 7, 1) # this doesn't actually work as twitter only goes back one week\n",
    "today = datetime.datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "outputfile_str = \"./DataSources/TwitterData/raw_tweets/raw_tweets_\" + today + \".csv\"\n",
    "print(outputfile_str)\n",
    "\n",
    "date_from, today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 Get tweets using a cursor\n",
    "- First we define our function to load tweets\n",
    "- Create search terms to query Twitter - return results as a list of dictionary items\n",
    "- Concatenate all returned results and then use this to create a pandas dataframe\n",
    "\n",
    "##### 1.1.3.1 define get_tweets\n",
    "In order to process quote tweets we borrowed code from https://blog.f-secure.com/processing-quote-tweets-with-twitter-api/ and then, because it didn't work well, searched on json.dumps and json.loads to work out how to strip out the json string for the quoted user and then to turn that into a dictionary I could easily interrogate\n",
    "- error processing purloined from https://stackoverflow.com/questions/27351207/gracefully-handle-errors-and-exceptions-for-user-timeline-method-in-tweepy\n",
    "    - error code 50 means there isn't a user for this user id\n",
    "    - error code 63 means this user id refers to a user who has been suspended from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "def get_tweets(search_words, my_api, today): \n",
    "    tic = time.perf_counter()\n",
    "    tweets = tweepy.Cursor(my_api.search,\n",
    "                       q=search_words,\n",
    "                       lang=\"en\",\n",
    "                       since=date_from).items()\n",
    "    \n",
    "    output = []\n",
    "    for tweet in tweets:\n",
    "               \n",
    "        try:\n",
    "            tweet_id = tweet.id\n",
    "            text = tweet.text\n",
    "            tweet_date = tweet.created_at\n",
    "            user_id_str = tweet.user.id_str\n",
    "            screen_name = tweet.user.screen_name\n",
    "            user_name = tweet.user.name\n",
    "            user_id = api.get_user(user_id_str)\n",
    "        \n",
    "            in_reply_to_user_screen_name = \"\"\n",
    "            quote_tweet_screen_name = \"\"\n",
    "            \n",
    "            if tweet.in_reply_to_user_id is not None: \n",
    "                in_reply_to_user_id = tweet.in_reply_to_user_id \n",
    "                in_reply_to_user_screen_name = api.get_user(in_reply_to_user_id).screen_name\n",
    "             \n",
    "            if hasattr(tweet, 'quoted_status'): \n",
    "                quote_tweet = tweet.quoted_status            \n",
    "                quote_tweet_str = json.dumps(quote_tweet._json) # dumps json component into a string\n",
    "                quote_tweet_dict = json.loads(quote_tweet_str) # loads the string into a dictionary                       \n",
    "                quote_tweet_id = quote_tweet_dict[\"user\"][\"id\"]\n",
    "                quote_tweet_screen_name = api.get_user(quote_tweet_id).screen_name\n",
    "                                  \n",
    "            user_location = user_id.location\n",
    "            user_coordinates = tweet.coordinates\n",
    "            favourite_count = tweet.favorite_count\n",
    "            retweet_count = tweet.retweet_count\n",
    "                \n",
    "            line = {'tweet_id' : tweet_id,\n",
    "                'tweet_date' : tweet_date,\n",
    "                'tweeter_id' : user_id_str,\n",
    "                'tweeter_user_name' : user_name,\n",
    "                'tweeter_screen_name' : screen_name,\n",
    "                'tweeter_location' : user_location,\n",
    "                'tweeter_coordinates' : user_coordinates,\n",
    "                'message_text' : text,\n",
    "                'in_reply_to_user_screen_name' : in_reply_to_user_screen_name,      \n",
    "                'quote_tweet_screen_name' : quote_tweet_screen_name,\n",
    "                'favourite_count' : favourite_count, \n",
    "                'retweet_count' : retweet_count,\n",
    "                'extract_run_date' : today,\n",
    "                'retrieved_using_search_term' : search_words}\n",
    "            output.append(line)\n",
    "        \n",
    "        except tweepy.TweepError as e:\n",
    "            print('\\n **************** error ***************')\n",
    "            print(e)\n",
    "            print('\\n ********* end of error text **********')\n",
    "               \n",
    "    toc = time.perf_counter()\n",
    "    time_taken = toc - tic\n",
    "    \n",
    "    print('Time taken to process search term : {} , was {:.2f}'.format(search_words, time_taken))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.3.2 create list of search terms and iteratively get tweets using these terms\n",
    "The search terms used were first investigated using Twitter itself to see which search terms retrieved a sizeable body of tweets. This is a manual and subjective process but is refined by reviewing the tweets returned as this exposes other potentially useful search terms. We also included the term sadiq khan in order to retrieve a larger body of tweets which might contain crime related topics that weren't retrieved using the more narrow search terms. However, as discussed previously, this search was very time consuming and frequently failed to complete because of time outs.\n",
    "- 'sadiq khan' search term successfully completed on 30/07/2021, 06/08/2021, 20/08/2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 661\n",
      "Rate limit reached. Sleeping for: 632\n",
      "Rate limit reached. Sleeping for: 680\n",
      "Rate limit reached. Sleeping for: 653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **************** error ***************\n",
      "[{'code': 50, 'message': 'User not found.'}]\n",
      "\n",
      " ********* end of error text **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 640\n"
     ]
    },
    {
     "ename": "TweepError",
     "evalue": "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    425\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    420\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1331\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1332\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1333\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mtimeout\u001b[0m: The read operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m             retries = retries.increment(\n\u001b[0m\u001b[0;32m    725\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 735\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    736\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    669\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_raise_timeout\u001b[1;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketTimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m             raise ReadTimeoutError(\n\u001b[0m\u001b[0;32m    336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Read timed out. (read timeout=%s)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m                     resp = self.session.request(self.method,\n\u001b[0m\u001b[0;32m    185\u001b[0m                                                 \u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTweepError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-35e310e1f762>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msearch_term\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msearch_terms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mcurrent_tweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_term\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoday\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mall_tweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_tweets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-850d73766bcf>\u001b[0m in \u001b[0;36mget_tweets\u001b[1;34m(search_words, my_api, today)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;31m# Reached end of current page, get the next page...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__self__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    190\u001b[0m                                                 proxies=self.api.proxy)\n\u001b[0;32m    191\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTweepError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Failed to send request: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[0mrem_calls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x-rate-limit-remaining'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    700\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;31m# Execute request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m                     resp = self.session.request(self.method,\n\u001b[0m\u001b[0;32m    185\u001b[0m                                                 \u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m                                                 \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    528\u001b[0m         }\n\u001b[0;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    527\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTweepError\u001b[0m: Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)"
     ]
    }
   ],
   "source": [
    "search_terms = [\"London AND knife AND crime\",\n",
    "                \"London AND knifecrime\",\n",
    "                \"Khan AND knife AND crime\",\n",
    "                \"Khan AND knifecrime\",\n",
    "                \"London AND violent AND crime\",\n",
    "                \"youth AND violent AND crime\",\n",
    "                \"youth AND crime AND London\"\n",
    "                \"youth AND knife AND crime\",\n",
    "                \"london AND youthcrime\",\n",
    "                \"#knifecrime AND #khan\",\n",
    "                \"#knifecrime AND #london\",\n",
    "                \"#violence AND #khan\",\n",
    "                \"#london AND #youthcrime\",\n",
    "                \"London AND crime\",\n",
    "                \"London AND stabbing\"]\n",
    "\n",
    "# The following term was queried on 30/07/2021, 06/08/2021, 20/08/2021  to get wider context on what's being tweeted\n",
    "#search_terms = [\"sadiq AND khan\"]\n",
    "\n",
    "all_tweets = []\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "for search_term in search_terms:\n",
    "    current_tweets = get_tweets(search_term, api, today)\n",
    "    all_tweets.append(current_tweets)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "time_taken = toc - tic\n",
    "    \n",
    "print('Time taken to process ALL search terms : {} , was {:.2f}'.format(search_terms, time_taken))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 create all_tweets_df dataframe\n",
    "First check on how many items downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df = pd.DataFrame(columns=['tweet_id', \n",
    "                                      'tweet_date', \n",
    "                                      'tweeter_id', \n",
    "                                      'tweeter_user_name', \n",
    "                                      'tweeter_screen_name', \n",
    "                                      'tweeter_location',\n",
    "                                      'tweeter_coordinates',\n",
    "                                      'message_text',\n",
    "                                      'in_reply_to_user_screen_name', \n",
    "                                      'quote_tweet_screen_name',\n",
    "                                      'favourite_count',\n",
    "                                      'retweet_count',\n",
    "                                      'extract_run_date',\n",
    "                                      'retrieved_using_search_term'])\n",
    "\n",
    "for these_tweets in all_tweets:\n",
    "    print('number of tweets in current list = {}'.format(len(these_tweets)))\n",
    "\n",
    "    df_tweets = pd.DataFrame(these_tweets)\n",
    "    all_tweets_df = all_tweets_df.append(df_tweets, ignore_index=True)\n",
    "\n",
    "print(all_tweets_df.shape)\n",
    "\n",
    "all_tweets_df.to_csv(outputfile_str, index=False)\n",
    "\n",
    "all_tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Load previously saved Twitter data\n",
    "- Need to change the file name passed to 'load_file_name' if we want a prior dataset\n",
    "- Will concatenate all these files in downstream notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_file_name = outputfile_str\n",
    "\n",
    "all_tweets_df_new = pd.read_csv(load_file_name)\n",
    "print(all_tweets_df_new.shape)\n",
    "all_tweets_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix A - Twitter Timeout error\n",
    "The following error message was received when extracting data using the search term \"Sadiq AND Khan\"\n",
    "\n",
    "### error message\n",
    "TimeoutError                              Traceback (most recent call last)\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py in _new_conn(self)\n",
    "    158         try:\n",
    "--> 159             conn = connection.create_connection(\n",
    "    160                 (self._dns_host, self.port), self.timeout, **extra_kw\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py in create_connection(address, timeout, source_address, socket_options)\n",
    "     83     if err is not None:\n",
    "---> 84         raise err\n",
    "     85 \n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py in create_connection(address, timeout, source_address, socket_options)\n",
    "     73                 sock.bind(source_address)\n",
    "---> 74             sock.connect(sa)\n",
    "     75             return sock\n",
    "\n",
    "TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "NewConnectionError                        Traceback (most recent call last)\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py in urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\n",
    "    669             # Make the request on the httplib connection object.\n",
    "--> 670             httplib_response = self._make_request(\n",
    "    671                 conn,\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py in _make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)\n",
    "    380         try:\n",
    "--> 381             self._validate_conn(conn)\n",
    "    382         except (SocketTimeout, BaseSSLError) as e:\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py in _validate_conn(self, conn)\n",
    "    975         if not getattr(conn, \"sock\", None):  # AppEngine might not have  `.sock`\n",
    "--> 976             conn.connect()\n",
    "    977 \n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py in connect(self)\n",
    "    307         # Add certificate verification\n",
    "--> 308         conn = self._new_conn()\n",
    "    309         hostname = self.host\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py in _new_conn(self)\n",
    "    170         except SocketError as e:\n",
    "--> 171             raise NewConnectionError(\n",
    "    172                 self, \"Failed to establish a new connection: %s\" % e\n",
    "\n",
    "NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x00000183218E7B50>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "MaxRetryError                             Traceback (most recent call last)\n",
    "~\\anaconda3\\lib\\site-packages\\requests\\adapters.py in send(self, request, stream, timeout, verify, cert, proxies)\n",
    "    438             if not chunked:\n",
    "--> 439                 resp = conn.urlopen(\n",
    "    440                     method=request.method,\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py in urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\n",
    "    723 \n",
    "--> 724             retries = retries.increment(\n",
    "    725                 method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py in increment(self, method, url, response, error, _pool, _stacktrace)\n",
    "    438         if new_retry.is_exhausted():\n",
    "--> 439             raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
    "    440 \n",
    "\n",
    "MaxRetryError: HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/users/show.json?id=862885892 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000183218E7B50>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "ConnectionError                           Traceback (most recent call last)\n",
    "~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py in execute(self)\n",
    "    183                 try:\n",
    "--> 184                     resp = self.session.request(self.method,\n",
    "    185                                                 full_url,\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\requests\\sessions.py in request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\n",
    "    529         send_kwargs.update(settings)\n",
    "--> 530         resp = self.send(prep, **send_kwargs)\n",
    "    531 \n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\requests\\sessions.py in send(self, request, **kwargs)\n",
    "    642         # Send the request\n",
    "--> 643         r = adapter.send(request, **kwargs)\n",
    "    644 \n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\requests\\adapters.py in send(self, request, stream, timeout, verify, cert, proxies)\n",
    "    515 \n",
    "--> 516             raise ConnectionError(e, request=request)\n",
    "    517 \n",
    "\n",
    "ConnectionError: HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/users/show.json?id=862885892 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000183218E7B50>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "TweepError                                Traceback (most recent call last)\n",
    "<ipython-input-7-c24d3d2b3d48> in <module>\n",
    "     18 \n",
    "     19 for search_term in search_terms:\n",
    "---> 20     current_tweets = get_tweets(search_term, api, today)\n",
    "     21     all_tweets.append(current_tweets)\n",
    "     22 \n",
    "\n",
    "<ipython-input-4-92b12659b409> in get_tweets(search_words, my_api, today)\n",
    "     16         screen_name = tweet.user.screen_name\n",
    "     17         user_name = tweet.user.name\n",
    "---> 18         user_id = api.get_user(user_id_str)\n",
    "     19         user_location = user_id.location\n",
    "     20         user_coordinates = tweet.coordinates\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py in _call(*args, **kwargs)\n",
    "    251                 return method\n",
    "    252             else:\n",
    "--> 253                 return method.execute()\n",
    "    254         finally:\n",
    "    255             method.session.close()\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py in execute(self)\n",
    "    190                                                 proxies=self.api.proxy)\n",
    "    191                 except Exception as e:\n",
    "--> 192                     six.reraise(TweepError, TweepError('Failed to send request: %s' % e), sys.exc_info()[2])\n",
    "    193 \n",
    "    194                 rem_calls = resp.headers.get('x-rate-limit-remaining')\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\six.py in reraise(tp, value, tb)\n",
    "    700                 value = tp()\n",
    "    701             if value.__traceback__ is not tb:\n",
    "--> 702                 raise value.with_traceback(tb)\n",
    "    703             raise value\n",
    "    704         finally:\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py in execute(self)\n",
    "    182                 # Execute request\n",
    "    183                 try:\n",
    "--> 184                     resp = self.session.request(self.method,\n",
    "    185                                                 full_url,\n",
    "    186                                                 data=self.post_data,\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\requests\\sessions.py in request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\n",
    "    528         }\n",
    "    529         send_kwargs.update(settings)\n",
    "--> 530         resp = self.send(prep, **send_kwargs)\n",
    "    531 \n",
    "    532         return resp\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\requests\\sessions.py in send(self, request, **kwargs)\n",
    "    641 \n",
    "    642         # Send the request\n",
    "--> 643         r = adapter.send(request, **kwargs)\n",
    "    644 \n",
    "    645         # Total elapsed time of the request (approximately)\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\requests\\adapters.py in send(self, request, stream, timeout, verify, cert, proxies)\n",
    "    514                 raise SSLError(e, request=request)\n",
    "    515 \n",
    "--> 516             raise ConnectionError(e, request=request)\n",
    "    517 \n",
    "    518         except ClosedPoolError as e:\n",
    "\n",
    "TweepError: Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/users/show.json?id=862885892 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000183218E7B50>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix B - Twitter academic research access\n",
    "As discussed, I applied for the research track as this offers access to historical twitter data and also the ability to download higher volumes of Tweets. Unfortunately my access requests were rejected.\n",
    "\n",
    "My original request failed, with Twitter responding that I did not meet their use case for a research account. I believe this is because they wanted to be able to reference my name via an official University website, for example within a Student directory. However, City University do not make student directories publicly available (for entirely understandable reasons), which suggests the research account isn't readily available to students and it is more aimed at researchers and faculty members who are referencable via the University website. I then reapplied using my city email address and having set up a Twitter account linked to this email address. I am waiting for a response (25/07/2021).\n",
    "- I received a response on 25/07/2021 saying my request did not \"qualify for academic access to the Twitter API\". Twitter do not give specific reasons and so it's not possible to understand whether they do not give access if they cannot identify students on a university directory or whether this specific research falls outside what they consider acceptable research (although they did say it qualified for regular developer access, which suggests the research topic was OK).\n",
    "\n",
    "I any case I go into detail on the application process because not having access to historic tweets significantly impacts our ability to perform the desired research and the process to get access is time consuming, opaque and there is no right to appeal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix C - Tweepy Error\n",
    "\n",
    "Rate limit reached. Sleeping for: 661\n",
    "Rate limit reached. Sleeping for: 632\n",
    "Rate limit reached. Sleeping for: 680\n",
    "Rate limit reached. Sleeping for: 653\n",
    "\n",
    "\n",
    "[{'code': 50, 'message': 'User not found.'}]\n",
    "\n",
    "\n",
    "Rate limit reached. Sleeping for: 640\n",
    "\n",
    "timeout                                   Traceback (most recent call last)\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py in _make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)\n",
    "    425                     # Otherwise it looks like a bug in the code.\n",
    "--> 426                     six.raise_from(e, None)\n",
    "    427         except (SocketTimeout, BaseSSLError, SocketError) as e:\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py in raise_from(value, from_value)\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py in _make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)\n",
    "    420                 try:\n",
    "--> 421                     httplib_response = conn.getresponse()\n",
    "    422                 except BaseException as e:\n",
    "\n",
    "~\\anaconda3\\lib\\http\\client.py in getresponse(self)\n",
    "   1331             try:\n",
    "-> 1332                 response.begin()\n",
    "   1333             except ConnectionError:\n",
    "\n",
    "~\\anaconda3\\lib\\http\\client.py in begin(self)\n",
    "    302         while True:\n",
    "--> 303             version, status, reason = self._read_status()\n",
    "    304             if status != CONTINUE:\n",
    "\n",
    "~\\anaconda3\\lib\\http\\client.py in _read_status(self)\n",
    "    263     def _read_status(self):\n",
    "--> 264         line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
    "    265         if len(line) > _MAXLINE:\n",
    "\n",
    "~\\anaconda3\\lib\\socket.py in readinto(self, b)\n",
    "    668             try:\n",
    "--> 669                 return self._sock.recv_into(b)\n",
    "    670             except timeout:\n",
    "\n",
    "~\\anaconda3\\lib\\ssl.py in recv_into(self, buffer, nbytes, flags)\n",
    "   1240                   self.__class__)\n",
    "-> 1241             return self.read(nbytes, buffer)\n",
    "   1242         else:\n",
    "\n",
    "~\\anaconda3\\lib\\ssl.py in read(self, len, buffer)\n",
    "   1098             if buffer is not None:\n",
    "-> 1099                 return self._sslobj.read(len, buffer)\n",
    "   1100             else:\n",
    "\n",
    "timeout: The read operation timed out\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "ReadTimeoutError                          Traceback (most recent call last)\n",
    "~\\anaconda3\\lib\\site-packages\\requests\\adapters.py in send(self, request, stream, timeout, verify, cert, proxies)\n",
    "    438             if not chunked:\n",
    "--> 439                 resp = conn.urlopen(\n",
    "    440                     method=request.method,\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py in urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\n",
    "    723 \n",
    "--> 724             retries = retries.increment(\n",
    "    725                 method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py in increment(self, method, url, response, error, _pool, _stacktrace)\n",
    "    402             if read is False or not self._is_method_retryable(method):\n",
    "--> 403                 raise six.reraise(type(error), error, _stacktrace)\n",
    "    404             elif read is not None:\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py in reraise(tp, value, tb)\n",
    "    734                 raise value.with_traceback(tb)\n",
    "--> 735             raise value\n",
    "    736         finally:\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py in urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\n",
    "    669             # Make the request on the httplib connection object.\n",
    "--> 670             httplib_response = self._make_request(\n",
    "    671                 conn,\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py in _make_request(self, conn, method, url, timeout, chunked, **httplib_request_kw)\n",
    "    427         except (SocketTimeout, BaseSSLError, SocketError) as e:\n",
    "--> 428             self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
    "    429             raise\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py in _raise_timeout(self, err, url, timeout_value)\n",
    "    334         if isinstance(err, SocketTimeout):\n",
    "--> 335             raise ReadTimeoutError(\n",
    "    336                 self, url, \"Read timed out. (read timeout=%s)\" % timeout_value\n",
    "\n",
    "ReadTimeoutError: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "ReadTimeout                               Traceback (most recent call last)\n",
    "~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py in execute(self)\n",
    "    183                 try:\n",
    "--> 184                     resp = self.session.request(self.method,\n",
    "    185                                                 full_url,\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\requests\\sessions.py in request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\n",
    "    529         send_kwargs.update(settings)\n",
    "--> 530         resp = self.send(prep, **send_kwargs)\n",
    "    531 \n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\requests\\sessions.py in send(self, request, **kwargs)\n",
    "    642         # Send the request\n",
    "--> 643         r = adapter.send(request, **kwargs)\n",
    "    644 \n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\requests\\adapters.py in send(self, request, stream, timeout, verify, cert, proxies)\n",
    "    528             elif isinstance(e, ReadTimeoutError):\n",
    "--> 529                 raise ReadTimeout(e, request=request)\n",
    "    530             else:\n",
    "\n",
    "ReadTimeout: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "TweepError                                Traceback (most recent call last)\n",
    "<ipython-input-5-35e310e1f762> in <module>\n",
    "     23 \n",
    "     24 for search_term in search_terms:\n",
    "---> 25     current_tweets = get_tweets(search_term, api, today)\n",
    "     26     all_tweets.append(current_tweets)\n",
    "     27 \n",
    "\n",
    "<ipython-input-4-850d73766bcf> in get_tweets(search_words, my_api, today)\n",
    "     10 \n",
    "     11     output = []\n",
    "---> 12     for tweet in tweets:\n",
    "     13 \n",
    "     14         try:\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py in __next__(self)\n",
    "     49 \n",
    "     50     def __next__(self):\n",
    "---> 51         return self.next()\n",
    "     52 \n",
    "     53     def next(self):\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py in next(self)\n",
    "    241         if self.current_page is None or self.page_index == len(self.current_page) - 1:\n",
    "    242             # Reached end of current page, get the next page...\n",
    "--> 243             self.current_page = self.page_iterator.next()\n",
    "    244             while len(self.current_page) == 0:\n",
    "    245                 self.current_page = self.page_iterator.next()\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py in next(self)\n",
    "    130 \n",
    "    131         if self.index >= len(self.results) - 1:\n",
    "--> 132             data = self.method(max_id=self.max_id, parser=RawParser(), *self.args, **self.kwargs)\n",
    "    133 \n",
    "    134             if hasattr(self.method, '__self__'):\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py in _call(*args, **kwargs)\n",
    "    251                 return method\n",
    "    252             else:\n",
    "--> 253                 return method.execute()\n",
    "    254         finally:\n",
    "    255             method.session.close()\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py in execute(self)\n",
    "    190                                                 proxies=self.api.proxy)\n",
    "    191                 except Exception as e:\n",
    "--> 192                     six.reraise(TweepError, TweepError('Failed to send request: %s' % e), sys.exc_info()[2])\n",
    "    193 \n",
    "    194                 rem_calls = resp.headers.get('x-rate-limit-remaining')\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\six.py in reraise(tp, value, tb)\n",
    "    700                 value = tp()\n",
    "    701             if value.__traceback__ is not tb:\n",
    "--> 702                 raise value.with_traceback(tb)\n",
    "    703             raise value\n",
    "    704         finally:\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py in execute(self)\n",
    "    182                 # Execute request\n",
    "    183                 try:\n",
    "--> 184                     resp = self.session.request(self.method,\n",
    "    185                                                 full_url,\n",
    "    186                                                 data=self.post_data,\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\requests\\sessions.py in request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\n",
    "    528         }\n",
    "    529         send_kwargs.update(settings)\n",
    "--> 530         resp = self.send(prep, **send_kwargs)\n",
    "    531 \n",
    "    532         return resp\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\requests\\sessions.py in send(self, request, **kwargs)\n",
    "    641 \n",
    "    642         # Send the request\n",
    "--> 643         r = adapter.send(request, **kwargs)\n",
    "    644 \n",
    "    645         # Total elapsed time of the request (approximately)\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\requests\\adapters.py in send(self, request, stream, timeout, verify, cert, proxies)\n",
    "    527                 raise SSLError(e, request=request)\n",
    "    528             elif isinstance(e, ReadTimeoutError):\n",
    "--> 529                 raise ReadTimeout(e, request=request)\n",
    "    530             else:\n",
    "    531                 raise\n",
    "\n",
    "TweepError: Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
