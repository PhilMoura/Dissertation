{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serious Violent Crime in London\n",
    "In the Crime Context notebook I established that serious violent crime comprises Violence against the Person, Robbery and Sexual Offences and Appendix B of that notebook details the crime sub categories which aggregate into these headline categories.\n",
    "    \n",
    "I also established that Home office data for <b> knife crime rates </b> for the Metropolitan Police were around 14,685 in 2019 while the total number of <b>Serious Violent Crimes </b> derived from aggregating the crimes for all of Londons Community Safety Partnerships was approaching 136,347, which means that knives are used in approximately 10.8% of all violent crimes. This reconciles with ONS estimates because they produce statistics showing the proportion of crimes by crime type in which knives were involved and this showed that 7-8% of the crime categories we used to filter London violent crime data involved knives (for years 2018 and 2019), which tallies with what we found. This means that the crime categories we are using are reasonable categories for assessing serious violent crime.\n",
    "\n",
    "The Home Office violent crime and knife crime can be found at https://www.gov.uk/government/statistics/police-recorded-crime-open-data-tables and the specific data we used were:\n",
    "- Serious Violent Crime: Police recorded crime Community Safety Partnership open data tables, from year ending March 2016 to year ending December 2020\n",
    "- Knife Crime: Offences involving knives or sharp instruments open data year ending March 2009 onwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## London Serious Crime Data (Overview)\n",
    "Our objective is to assess whether using official sources of socio economic, demographic, crime and policing data at local area level, that youth violent crime is more highly correlated with deprivation than levels of policing and crime cleanup rates in London? \n",
    "\n",
    "### Available data sources\n",
    "In order to do this we need youth violent crime data at a low level of granularity (LSOA).The London Assembly analysis produced violent crime data by aggregating Metropolitan Police serious youth violence crime offences, British Transport Police violent crime offences, London Ambulance assuault call-outs and hospital A&E data and admission episodes for assault ( https://data.london.gov.uk/dataset/a-public-health-approach-to-serious-youth-violence - 04d Appendix B - Data pack 2018). The reason for using these additional sources is because they believe that only 50% of serious youth violence offences were reported to the police. Using these additional sources creates a fuller picture of knife crimes. \n",
    "\n",
    "Unfortunately, it is not possible to recreate this dataset because ambulance callout and hospital A&E data is sensitive data and not publicly available at the level of granularity we require. We contacted CityIntelligence, owner of the London Data Store on May 20th 2021 to request access to their data but did not receive a response. Furthermore, even if we could access this data, we do not have the means to cross reference which cases have also been captured within Police reported crime data and so there would be a significant risk of double counting. For this reason we chose to rely on police reported crime data.\n",
    "\n",
    "Police recorded crime data is produced in two forms, firstly the Crime Survey in England & Wales (CSEW), which entails surveys of the victims of crime and secondly in crime statistics collated by the police forces. In discussing Serious Youth Violence ( https://publications.parliament.uk/pa/cm201719/cmselect/cmhaff/1016/1016.pdf ), the Home Affairs Committee of the House of Commons The Crime Survey in England & Wales explain how police collated statistics are their preferred source of serious crime data because, while the CSEW is a better source for more minor crimes, \"it is is not very effective at measuring high-harm offences\" (page 10). For this reason we will base our violent crime data on crime statistics produced by the The Metropolitan police. There are two sources for these statistics: \n",
    "- the London Datastore https://data.london.gov.uk/dataset/recorded_crime_summary \n",
    "- police data available from https://data.police.uk/data/ (we were specifically directed to this site by members of the Home Office crime team).\n",
    "\n",
    "For the purposes of this research, we want to produce a clean dataset of LSOA level crime for the year 2019 (year starting in April, 2019 and running through to end of March 2020). We specifically chose this period because there it is the latest full years worth of data that was not materially affected by the Covid pandemic (which escalated in April 2020. We wanted a later year because that gives more time for any of the Mayors actions (or inactions) to have had an effect on crime figures.\n",
    "\n",
    "### Reconciling data sources and choosing the best source\n",
    "Within this notebook we go through the process of reconciling each of these sources with the Home Office data previously analysed so that we choose the best available source for serious violent crime data. In all three cases we will be reconciling data from the financial year 2019.\n",
    "\n",
    "In summary, neither dataset reconciles closely with the Home Office data but the data.police data is the slightly better fit and so we chose to use that as our primary source, particularly given it includes sexual offences data. However, it is worth noting the following limitations we observed.\n",
    "\n",
    "- London Datastore\n",
    "    - LSOA level data does not contain sexual offences, which as we discussed previously, is one of the crime categories the Home Office includes within its serious violent crime statistics. However, these numbers are included within the Ward level data available from the same website and so we used that to identify what proportion of all violent crimes were sexual offences. We found that, for financial year 2017 data, this comprised between 5 and 7% of all serious violent crime and so we believe that the remaining data, without sexual offences, could have been a reasonable proxy for serious violent crime.\n",
    "    - The violence against the person sub categories are different between the 'latest' dataset and Home Office dataset because of changes to crime recording categories and so this means reconciling between the two sources could be problematic (we test for this in this notebook). These new categories are as follows:\n",
    "         - Violence against the person: Homicide / Violence with Injury / Violence without Injury\n",
    "         - Robbery: Robbery of Business Property / Robbery of Personal Property (we ignore robbery of business property in our analysis)\n",
    "    - The 'latest' dataset on this site is updated every quarter and contains the prior 2 years on a rolling basis. This means that the version used for this analysis, (which was extracted in February 2021), contains data for January-Aril 2019 while the latest version on data.london (as of 14th June 2021) has data starting in May 2019. This isn't a problem with the analysis but it is mentioned because it affects replicability from original sources. \n",
    "    \n",
    "- Police Data\n",
    "    - There were a few LSOAs that did not have crime figures and for these we substituted the London Datastore numbers\n",
    "    - This data has a single category 'Violence and sexual offences' for 'Violence against the Person' instead of the categories used in the Home Office data and it is likely this will lead to inconsistencies in which crimes are included.  \n",
    "    - Similarly to the London Datastore, the police.data only presents the prior 2 years on a rolling basis, which means that this isn't an issue for our analysis (apart from trend analysis discussed below) but it does mean the research is not repeatable from original sources.\n",
    "    \n",
    "- Both\n",
    "    - Publicly available police data does not provide the age of the perpetrator and so it is not possible to isolate youth crime from this data. However, in response from the Metropolitan Police to a freedom of information request ( https://www.met.police.uk/SysSiteAssets/foi-media/metropolitan-police/disclosure_2019/january_2019/information-rights-unit---victims-and-perpetrators-data-for-violent-crimes-from-may-2015-to-november-2018 ) we can see that approximately 19% of all serious crime is perpetrated by youths under the age of 20 and nearly 45% perpetrated by persons under the age of 30. Using these numbers it is reasonable to predict that between 30-35% of serious violent crimes are perpetrated by youths if we use the London definition of youths, which is persons under the age of 25. This is a sizeable enough proportion to use the overall serious violent crime statistics as a proxy for youth violent crime. However, it is important to note that the distribution of youths across different LSOA could be different and we will be mindful of this in our later analysis, and clearly reference our assumptions when discussing any results.  \n",
    "\n",
    "### Chosen Data Source\n",
    "The <b>Police Data source is shown to be the better source for our research</b> because it contains sexual offences and reconciles more closely with the Home Office data.\n",
    "\n",
    "## Crime trends over time\n",
    "The final contextual analysis we perform is to see how serious violent crime has trended between 2018 and 2019. This is to understand whether the trends are consistent across London or whether there are significant variations between neighbourhoods. It should be noted we would have prefered to measure changes between 2017 and 2019 but the 2017 data is only available in archived form at police.data and they recommend against using archived data for analysis. This means we have to use the current dataset which only contains the past two years crime data on a rolling basis. This creates an issue because the earliest dataset available was May 2018, which means we have two issues:\n",
    "- all other crime data is aggregated between April and the following March but we will have to aggregate between May and the following April.\n",
    "- the 2019 data for trend analysis will include data from April 2020, by which time the pandemic lockdown would have started and hence the crime levels would have been far lower for that moment. \n",
    "\n",
    "However, we believe we still have two seperate years worth of data to compare the trend and also we make the assumption that lockdown will have affected all boroughs in similar ways and so this isn't too sigificant an issue if we are purely using it to report trends. Again, this will be clearly explained in our results. \n",
    "\n",
    "## London Crime Data Analysis\n",
    "blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## London Serious Crime Data (Analysis)\n",
    "\n",
    "### First derive the proportion of all serious violent crime from sexual offences using ward level data\n",
    "The London datastore does contain crime data at ward level and this data does contain Sexual Offences data and so we will use this dataset to first establish what proportion of Serious Violent Crime is comprised of Sexual Offences. This will allow us to assess whether the absence of this data in the LSOA level data will have material impact on our analysis.\n",
    "- It should be noted that we could have used Ward data for our analysis but chose not to because it is not sufficiently granular, for example wards comprise on average 13,078 people while LSOAs contain 1,722 (2010 figures, source: https://data.london.gov.uk/dataset/lsoa-atlas#:~:text=The%20LSOA%20atlas%20provides%20a,and%2013%2C078%20for%20a%20ward )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_crimes = pd.read_excel(\".\\DataSources\\Crime and outcomes\\MPS_Ward_Level_Crime_Historic_NewWard (Jan2017 to Dec2018).xlsx\",\n",
    "                           sheet_name='data', usecols=\"A:E, CI:DF\")\n",
    "print(all_crimes.shape)\n",
    "all_crimes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_crimes = all_crimes.dropna(how='all') # only drops a row when every column is NA\n",
    "print(all_crimes.shape)\n",
    "\n",
    "# Now check for NaN values\n",
    "nan_values = all_crimes[all_crimes.isna().any(axis=1)]\n",
    "nan_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violent_crimes = all_crimes[all_crimes['Minor Category'].isin(['Assault with Injury',\n",
    "                                                          'Common Assault',\n",
    "                                                          'Harassment',\n",
    "                                                          'Murder',\n",
    "                                                          'Offensive Weapon',\n",
    "                                                          'Other Sexual',\n",
    "                                                          'Other Violence',\n",
    "                                                          'Personal Property',\n",
    "                                                          'Rape',\n",
    "                                                          'Wounding/GBH'])].copy()\n",
    "\n",
    "print(violent_crimes.shape)\n",
    "violent_crimes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violent_crimes['total_FY2017'] = violent_crimes[201704] + violent_crimes[201705] + violent_crimes[201706] + \\\n",
    "                                violent_crimes[201707] + violent_crimes[201708] + violent_crimes[201709] + \\\n",
    "                                violent_crimes[201710] + violent_crimes[201711] + violent_crimes[201712] + \\\n",
    "                                violent_crimes[201801] + violent_crimes[201802] + violent_crimes[201803]\n",
    "\n",
    "violent_crimes.rename(columns = {'WardCode':'ward_code'}, inplace = True)\n",
    "violent_crimes.rename(columns = {'Ward Name':'ward_name'}, inplace = True)\n",
    "violent_crimes.rename(columns = {'Borough':'borough'}, inplace = True)\n",
    "violent_crimes.rename(columns = {'Major Category':'major_category'}, inplace = True)\n",
    "violent_crimes.rename(columns = {'Minor Category':'minor_category'}, inplace = True)\n",
    "\n",
    "violent_crimes_FY2017 = violent_crimes[['ward_code', 'ward_name', 'borough', 'major_category', 'minor_category', 'total_FY2017']].copy()\n",
    "\n",
    "print(violent_crimes_FY2017.shape)\n",
    "violent_crimes_FY2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_totals_FY2017 = violent_crimes_FY2017.groupby([\"borough\"]).apply(lambda x: x['total_FY2017'].sum()).reset_index()\n",
    "borough_totals_FY2017.rename(columns = {0:'total'}, inplace = True)\n",
    "print(borough_totals_FY2017.shape)\n",
    "borough_totals_FY2017.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sexual_crimes = violent_crimes_FY2017[violent_crimes_FY2017.major_category == 'Sexual Offences']\n",
    "\n",
    "borough_totals_FY2017_sexual = sexual_crimes.groupby([\"borough\"]).apply(lambda x: x['total_FY2017'].sum()).reset_index()\n",
    "borough_totals_FY2017_sexual.rename(columns = {0:'total'}, inplace = True)\n",
    "print(borough_totals_FY2017_sexual.shape)\n",
    "borough_totals_FY2017_sexual.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_proportion = pd.merge(borough_totals_FY2017_sexual, borough_totals_FY2017, how='inner', left_on='borough', right_on = 'borough')\n",
    "\n",
    "print(sex_proportion.shape)\n",
    "sex_proportion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_proportion['pct_oftotal'] = sex_proportion.total_x / sex_proportion.total_y\n",
    "\n",
    "print(\"Sexual Offences: maximum percentage of total across all boroughs = {0:.2%}, minimum = {1:.2%}\".format(sex_proportion.pct_oftotal.max(), sex_proportion.pct_oftotal.min()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sexual proportion comments\n",
    "The range of all serious violent crimes arising through sexual offences is between 5 and 7%. We believe this is not sufficiently material to reject the London datastore LSOA level serious violent crime data purely because it doesn't contain sexual offences.\n",
    "\n",
    "## Load London serious violent crime data at LSOA level\n",
    "We will now load both the Police data and London Datastore crime data at LSOA level for financial year 2019. We will then compare each to the previously produced Home Office data to see which of the two more closely reconciles with it. This is provides a sense check to understand how well the London Datastore data mirrors Home Office data and the extent to which using the newer classifications changes the crime numbers.\n",
    "\n",
    "We will then choose that dataset as our primary source for serious violent crime. It should be noted that we previously created two Home Office Serious Violent Crime extracts, one with and the other without Sexual Offences. We will use these files to perform the reconciliations. This is because the Police dataset does contain sexual offences while the London Datastore data does not.\n",
    "\n",
    "### Load London datastore crime data for FY2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_crimes = pd.read_excel(\".\\DataSources\\Crime and outcomes\\MPS LSOA Level Crime (Jan2019 to Dec2020).xlsx\",sheet_name='MPS LSOA Level Crime (most rece')\n",
    "print(all_crimes.shape)\n",
    "all_crimes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_crimes = all_crimes.dropna(how='all') # only drops a row when every column is NA\n",
    "print(all_crimes.shape)\n",
    "\n",
    "# Now check for NaN values\n",
    "nan_values = all_crimes[all_crimes.isna().any(axis=1)]\n",
    "nan_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### London Datastore - Serious Violent Crime categories\n",
    "The major categories and Robbery and Violence against the Person but we filter data on minor category because we want to exclude 'Robbery of Business Property'. Having done that, we then aggregate the monthly crime figures to produce a single serious violent crime number per LSOA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violent_crimes = all_crimes[all_crimes['Minor Category'].isin(['Homicide',\n",
    "                                                          'Robbery of Personal Property',\n",
    "                                                          'Violence with Injury',\n",
    "                                                          'Violence without Injury'])].copy()\n",
    "\n",
    "violent_crimes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violent_crimes['total'] = violent_crimes[201904] + violent_crimes[201905] + violent_crimes[201906] + \\\n",
    "                                violent_crimes[201907] + violent_crimes[201908] + violent_crimes[201909] + \\\n",
    "                                violent_crimes[201910] + violent_crimes[201911] + violent_crimes[201912] + \\\n",
    "                                violent_crimes[202001] + violent_crimes[202002] + violent_crimes[202003]\n",
    "\n",
    "violent_crimes.rename(columns = {'LSOA Code':'lsoa_code'}, inplace = True)\n",
    "violent_crimes.rename(columns = {'Borough':'borough'}, inplace = True)\n",
    "violent_crimes.rename(columns = {'Major Category':'major_category'}, inplace = True)\n",
    "violent_crimes.rename(columns = {'Minor Category':'minor_category'}, inplace = True)\n",
    "\n",
    "violent_crimes_2019 = violent_crimes[['lsoa_code', 'borough', 'major_category', 'minor_category', 'total']].copy()\n",
    "\n",
    "print(violent_crimes_2019.shape)\n",
    "violent_crimes_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_datastore_by_lsoa = violent_crimes_2019.groupby([\"lsoa_code\", \"borough\"]).apply(lambda x: x['total'].sum()).reset_index()\n",
    "ldn_datastore_by_lsoa.rename(columns = {0:'ldn_datastore_total'}, inplace = True)\n",
    "print(ldn_datastore_by_lsoa.shape)\n",
    "ldn_datastore_by_lsoa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load police data crime data for FY2019\n",
    "This data is spread across a number of directories/files, with each file containing crime data for a single month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_file = \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2019/2019-04/2019-04-metropolitan-street.csv\"\n",
    "\n",
    "files = [\"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2019/2019-05/2019-05-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2019/2019-06/2019-06-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2019/2019-07/2019-07-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2019/2019-08/2019-08-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2019/2019-09/2019-09-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2019/2019-10/2019-10-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2019/2019-11/2019-11-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2019/2019-12/2019-12-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2019/2020-01/2020-01-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2019/2020-02/2020-02-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2019/2020-03/2020-03-metropolitan-street.csv\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df, description, year):\n",
    "    \n",
    "    print(\"<--- transforming \" + description + \" --->\\n\")\n",
    "    print(\"initial shape\")\n",
    "    print(df.shape)\n",
    "    \n",
    "    df = df.dropna(how='all') # only drops a row when every column is NA\n",
    "    \n",
    "    print(\"shape after removing rows with all nulls\")\n",
    "    print(df.shape)\n",
    "    \n",
    "    df = df[['LSOA code', 'LSOA name', 'Month', 'Crime type']]    \n",
    "    df = df[~df['LSOA code'].isna()]\n",
    "    \n",
    "    df['year'] = year\n",
    "    \n",
    "    print(\"shape after trimming columns and removing rows with LSOA = NaN\")\n",
    "    print(df.shape)\n",
    "    \n",
    "    # Now check for any NaN values\n",
    "    nan_values = df[df.isna().any(axis=1)]\n",
    "    \n",
    "    print(\"number of rows in nan_values\")\n",
    "    print(nan_values.shape[0])\n",
    "    \n",
    "    return df\n",
    "    \n",
    "df_raw = pd.read_csv(first_file)\n",
    "all_crime = transform_df(df_raw, first_file, '2019')\n",
    "\n",
    "print(all_crime.shape)\n",
    "all_crime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_file in files:\n",
    "    df_raw = pd.read_csv(this_file)\n",
    "    df = transform_df(df_raw, this_file, '2019')\n",
    "    all_crime = pd.concat([all_crime, df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "There were a number of entries which aren't useable because they don't have an LSOA code. These entries have been stripped out. There were no entries where all items were NaN and apart from LSOA code, there weren't any other items with NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violent_crime_monthly = all_crime[(all_crime['Crime type'] == 'Violence and sexual offences') | \n",
    "                                 (all_crime['Crime type'] == 'Robbery')].copy()\n",
    "\n",
    "print(violent_crime_monthly.shape)\n",
    "violent_crime_monthly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_data_by_lsoa = violent_crime_monthly.groupby([\"LSOA code\"]).apply(lambda x: x['Month'].count()).reset_index()\n",
    "police_data_by_lsoa.rename(columns = {0:'police_total'}, inplace = True)\n",
    "\n",
    "print(police_data_by_lsoa.shape)\n",
    "police_data_by_lsoa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now merge the Police data with the London Data crime data\n",
    "I left join because I know the police data has erroneous rows for Wales, Bolton, Salford while London Gov data is only for London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violent_crime_by_lsoa = pd.merge(ldn_datastore_by_lsoa, police_data_by_lsoa, how='left', left_on='lsoa_code', right_on = 'LSOA code')\n",
    "\n",
    "print(violent_crime_by_lsoa.shape)\n",
    "violent_crime_by_lsoa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substitute values into police_total where LSOA code was NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violent_crime_by_lsoa[violent_crime_by_lsoa['LSOA code'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violent_crime_by_lsoa.loc[violent_crime_by_lsoa['LSOA code'].isna(), 'police_total'] = violent_crime_by_lsoa.ldn_datastore_total\n",
    "violent_crime_by_lsoa[violent_crime_by_lsoa['LSOA code'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violent_crime_by_lsoa.drop('LSOA code', axis=1, inplace=True)\n",
    "violent_crime_by_lsoa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconcile at Borough level with Home Office data\n",
    "We will now reconcile both London Datastore and Police Data serious violent crime data with Home Office data to see which reconciles more closely. It should be remembered that London datastore does not include sexual offences with police data does. So they will be reconciled against two different versions of the Home Office data, one with sexual offences and one without.\n",
    "\n",
    "#### Home Office data is at borough level so both our crime datasets need to be aggregated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_totals_ldn = violent_crime_by_lsoa.groupby([\"borough\"]).apply(lambda x: x['ldn_datastore_total'].sum()).reset_index()\n",
    "borough_totals_ldn.rename(columns = {0:'ldn_datastore_total'}, inplace = True)\n",
    "print(borough_totals_ldn.shape)\n",
    "borough_totals_ldn.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_totals_police = violent_crime_by_lsoa.groupby([\"borough\"]).apply(lambda x: x['police_total'].sum()).reset_index()\n",
    "borough_totals_police.rename(columns = {0:'police_total'}, inplace = True)\n",
    "print(borough_totals_police.shape)\n",
    "borough_totals_police.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_totals_2019 = pd.merge(borough_totals_police, borough_totals_ldn, how='inner', \n",
    "                               left_on='borough', right_on = 'borough')\n",
    "\n",
    "print(borough_totals_2019.shape)\n",
    "borough_totals_2019.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and merge Home Office Serious Violent Crime Data\n",
    "Need to load both with and without sexual offences data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_csp_notsex = pd.read_csv('.\\DataSources\\England and Wales Crime Data\\london_csp_notsex.csv')\n",
    "\n",
    "london_csp_notsex_2019 = london_csp_notsex[['csp_name', 'total']][london_csp_notsex.year == 2019].copy()\n",
    "\n",
    "london_csp_notsex_2019.rename(columns = {'total':'total_notsex'}, inplace = True)\n",
    "\n",
    "print(london_csp_notsex_2019.shape)\n",
    "london_csp_notsex_2019.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_csp_sex = pd.read_csv('.\\DataSources\\England and Wales Crime Data\\london_csp.csv')\n",
    "\n",
    "london_csp_sex_2019 = london_csp_sex[['csp_name', 'total']][london_csp_sex.year == 2019].copy()\n",
    "london_csp_sex_2019.rename(columns = {'total':'total_sex'}, inplace = True)\n",
    "\n",
    "print(london_csp_sex_2019.shape)\n",
    "london_csp_sex_2019.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_csp_2019 = pd.merge(london_csp_sex_2019, london_csp_notsex_2019, how='inner', left_on='csp_name', right_on = 'csp_name')\n",
    "\n",
    "print(london_csp_2019.shape)\n",
    "london_csp_2019.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_borough = pd.merge(borough_totals_2019, london_csp_2019, how='inner', left_on='borough', right_on = 'csp_name')\n",
    "\n",
    "violence_borough.drop('csp_name', axis=1, inplace=True)\n",
    "\n",
    "violence_borough['pct_diff_nosex'] = (violence_borough.ldn_datastore_total - violence_borough.total_notsex) / violence_borough.total_notsex\n",
    "violence_borough['pct_diff_sex'] = (violence_borough.police_total - violence_borough.total_sex) / violence_borough.total_sex\n",
    "\n",
    "print(violence_borough.shape)\n",
    "violence_borough.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steelblue = 'rgb(70,130,180)'\n",
    "\n",
    "bars = alt.Chart(violence_borough[['borough', 'ldn_datastore_total']], title='Serious Violent Crime by borough (London Datastore)').mark_bar(opacity=0.6, color='firebrick').encode(\n",
    "    x=alt.X('ldn_datastore_total:Q', axis=alt.Axis(title='total (2019)', ticks=False)),\n",
    "    y=alt.Y('borough:N', axis=alt.Axis(title=None, ticks=False), sort='-x'),  \n",
    "    #color=alt.Color('borough:N', legend=None)\n",
    ")\n",
    "\n",
    "text = alt.Chart(violence_borough[['borough', 'ldn_datastore_total']]).mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    color='white',\n",
    "    dx=-20  # Nudges text to right so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    x=alt.X('ldn_datastore_total:Q', axis=alt.Axis(title='total (2019)', ticks=False)),\n",
    "    y=alt.Y('borough:N', axis=alt.Axis(title=None, ticks=False), sort='-x'),  \n",
    "    text=alt.Text('ldn_datastore_total:Q', format=',.4r')\n",
    ")\n",
    "\n",
    "bars_1 = alt.Chart(violence_borough[['borough', 'total_notsex']], title='Serious Violent Crime by borough (Home Office, no sexual offences)').mark_bar(opacity=0.6, color=steelblue).encode(\n",
    "    x=alt.X('total_notsex:Q', axis=alt.Axis(title='total (2019)', ticks=False)),\n",
    "    y=alt.Y('borough:N', axis=alt.Axis(title=None, ticks=False), sort='-x'),  \n",
    "    #color=alt.Color('borough:N', legend=None)\n",
    ")\n",
    "\n",
    "text_1 = alt.Chart(violence_borough[['borough', 'total_notsex']]).mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    color='white',\n",
    "    dx=-20  # Nudges text to right so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    x=alt.X('total_notsex:Q', axis=alt.Axis(title='total (2019)', ticks=False)),\n",
    "    y=alt.Y('borough:N', axis=alt.Axis(title=None, ticks=False), sort='-x'),  \n",
    "    text=alt.Text('total_notsex:Q', format=',.4r')\n",
    ")\n",
    "\n",
    "ldn_datastore_total = (bars + text).properties(height=600, width=300)\n",
    "homeoffice_nosex = (bars_1 + text_1).properties(height=600, width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_2 = alt.Chart(violence_borough[['borough', 'police_total']], title='Serious Violent Crime by borough (Police Data)').mark_bar(opacity=0.6, color='firebrick').encode(\n",
    "    x=alt.X('police_total:Q', axis=alt.Axis(title='total (2019)', ticks=False)),\n",
    "    y=alt.Y('borough:N', axis=alt.Axis(title=None, ticks=False), sort='-x'),  \n",
    "    #color=alt.Color('borough:N', legend=None)\n",
    ")\n",
    "\n",
    "text_2 = alt.Chart(violence_borough[['borough', 'police_total']]).mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    color='white',\n",
    "    dx=-20  # Nudges text to right so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    x=alt.X('police_total:Q', axis=alt.Axis(title='total (2019)', ticks=False)),\n",
    "    y=alt.Y('borough:N', axis=alt.Axis(title=None, ticks=False), sort='-x'),  \n",
    "    text=alt.Text('police_total:Q', format=',.4r')\n",
    ")\n",
    "\n",
    "bars_3 = alt.Chart(violence_borough[['borough', 'total_sex']], title='Serious Violent Crime by borough (Home Office, incl. sexual offences)').mark_bar(opacity=0.6, color=steelblue).encode(\n",
    "    x=alt.X('total_sex:Q', axis=alt.Axis(title='total (2019)', ticks=False)),\n",
    "    y=alt.Y('borough:N', axis=alt.Axis(title=None, ticks=False), sort='-x'),  \n",
    "    #color=alt.Color('borough:N', legend=None)\n",
    ")\n",
    "\n",
    "text_3 = alt.Chart(violence_borough[['borough', 'total_sex']]).mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    color='white',\n",
    "    dx=-20  # Nudges text to right so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    x=alt.X('total_sex:Q', axis=alt.Axis(title='total (2019)', ticks=False)),\n",
    "    y=alt.Y('borough:N', axis=alt.Axis(title=None, ticks=False), sort='-x'),  \n",
    "    text=alt.Text('total_sex:Q', format=',.4r')\n",
    ")\n",
    "\n",
    "police_data_total = (bars_2 + text_2).properties(height=600, width=300)\n",
    "homeoffice_sex = (bars_3 + text_3).properties(height=600, width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ldn_datastore_total | homeoffice_nosex).configure_axis(\n",
    "    grid=False,\n",
    "    domain=False\n",
    ").configure_view(\n",
    "    strokeWidth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(police_data_total | homeoffice_sex).configure_axis(\n",
    "    grid=False,\n",
    "    domain=False\n",
    ").configure_view(\n",
    "    strokeWidth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_4 = alt.Chart(violence_borough[['borough', 'pct_diff_nosex']], title='Home Office v London Datastore, percent difference by borough').mark_bar(opacity=0.6, color='firebrick').encode(\n",
    "    x=alt.X('pct_diff_nosex:Q', axis=alt.Axis(title='total (2019)', ticks=False, format='%')),\n",
    "    y=alt.Y('borough:N', axis=alt.Axis(title=None, ticks=False), sort='x'),  \n",
    "    #color=alt.Color('borough:N', legend=None)\n",
    ")\n",
    "\n",
    "text_4 = alt.Chart(violence_borough[['borough', 'pct_diff_nosex']]).mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    color='white',\n",
    "    dx=-20  # Nudges text to right so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    x=alt.X('pct_diff_nosex:Q', axis=alt.Axis(title='total (2019)', ticks=False)),\n",
    "    y=alt.Y('borough:N', axis=alt.Axis(title=None, ticks=False), sort='x'),  \n",
    "    text=alt.Text('pct_diff_nosex:Q', format='.1%')\n",
    ")\n",
    "\n",
    "bars_5 = alt.Chart(violence_borough[['borough', 'pct_diff_sex']], title='Home Office v Police Data, percent difference by borough').mark_bar(opacity=0.6, color='steelblue').encode(\n",
    "    x=alt.X('pct_diff_sex:Q', axis=alt.Axis(title='total (2019)', ticks=False, format='%')),\n",
    "    y=alt.Y('borough:N', axis=alt.Axis(title=None, ticks=False), sort='x'),  \n",
    "    #color=alt.Color('borough:N', legend=None)\n",
    ")\n",
    "\n",
    "text_5 = alt.Chart(violence_borough[['borough', 'pct_diff_sex']]).mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    color='black',\n",
    "    dx= 20  # Nudges text to right so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    x=alt.X('pct_diff_sex:Q', axis=alt.Axis(title='total (2019)', ticks=False)),\n",
    "    y=alt.Y('borough:N', axis=alt.Axis(title=None, ticks=False), sort='x'),  \n",
    "    text=alt.Text('pct_diff_sex:Q', format='.1%')\n",
    ")\n",
    "\n",
    "ldn_home_rec = (bars_4 + text_4).properties(height=600, width=300)\n",
    "police_home_rec = (bars_5 + text_5).properties(height=600, width=300)\n",
    "\n",
    "\n",
    "(ldn_home_rec | police_home_rec).configure_axis(\n",
    "    grid=False,\n",
    "    domain=False\n",
    ").configure_view(\n",
    "    strokeWidth=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconciliation comments\n",
    "The percent differences between police and home office data are smaller and also the police data contains sexual offences and so this dataset is a better choice than the london datasetore dataset. However, it should be noted that the size of the differences is large, up to 43%, which means the difference in recording categories has a material effect and this will be explicitly stated within the results. However, the order of boroughs hasn't changed substantially i.e. of the top 10  Police Data boroughs, 9 are in the top 10 home office boroughs and slight differences in ranking in the top 10 are due to reasonably small differences in the numbers. Likewise, 9 of the bottom ten Police data boroughs are in the bottom 10 home office boroughs and so the <b> RELATIVE </b> magnitudes seem fairly consistent. So, while the difference in crime totals are sizeable, the extent of crimes in each boroughs are consistent in relative terms and so we believe this is a good enough basis on which to continue.\n",
    "\n",
    "#### Reconciliation with GLA research\n",
    "GLA research (14 July Update) found that the boroughs which had the highest number of police-recorded SYV victims were (police office data ranking in brackets): \n",
    "- Westminster (1)\n",
    "- Southwark (9)\n",
    "- Tower Hamlets (8)\n",
    "- Haringey (3)\n",
    "- Enfield (18)\n",
    "- Lambeth (6)\n",
    "- Croydon (13)\n",
    "- Brent (5)\n",
    "- Newham (7)\n",
    "\n",
    "The boroughs with the highest <b>RATES</b> of police-recorded victimisation amongst 1-24 year olds were Westminster,\n",
    "Haringey, Southwark, Lambeth, Islington, Tower Hamlets, Camden, and Hackney. The GLA analysis suggests the differences between levels and rates of victimation can be due to the youth proportion in a borough and also how localised serious youth violence is, and neither of these are captured within the Police Data crime figures. This could explain some of the difference in the rankings but, as discussed previously, the Police Data does not report the age of the victim or perpetrator and so it is not possible to more closely mirror the GLA research. This will be reported within the results. \n",
    "\n",
    "## Crime Context for London\n",
    "We now want to see crime per 1000 inhabitants and also to see how crime is distributed across london LSOAs. To do this we need population data, which we extract from https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/lowersuperoutputareamidyearpopulationestimates (for mid 2019 estimates) and then merge it with the crime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load population data\n",
    "population_data = pd.read_excel(\".\\DataSources\\Population\\SAPE22DT2-mid-2019-lsoa-syoa-estimates-unformatted.xlsx\",sheet_name='Mid-2019 Persons', skiprows=4,\n",
    "                           usecols=\"A, B, G\")\n",
    "\n",
    "population_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with crime data\n",
    "violent_crimes_new = pd.merge(violent_crime_by_lsoa, population_data, left_on='lsoa_code', right_on='LSOA Code', how = 'inner')\n",
    "violent_crimes_new.rename(columns = {'LSOA Name':'lsoa_name'}, inplace = True)\n",
    "violent_crimes_new.rename(columns = {'All Ages':'population'}, inplace = True)\n",
    "\n",
    "violent_crimes_new['crime_per_1000'] = 1000 * violent_crimes_new.police_total / violent_crimes_new.population\n",
    "\n",
    "total_per_1000 = violent_crimes_new.crime_per_1000.sum()\n",
    "\n",
    "# multiply by 1000 so we don't have tiny numbers\n",
    "violent_crimes_new['crime_per_1000_proportion'] = 1000 * violent_crimes_new.crime_per_1000 / total_per_1000\n",
    "\n",
    "violent_crimes_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "london_map = gpd.read_file(\"./DataSources/Shapefiles/LSOA_2011_London_gen_MHW.shp\") # a gis format that has geographical boundaries QGIS is a package for looking at shape files\n",
    "london_map.crs = \"epsg:27700\" # code for the UK national grid\n",
    "\n",
    "london_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load centroids so we can position our bubbles\n",
    "lsoa_centroids= pd.read_csv(\"./DataSources/Shapefiles/centroids_lsoa.csv\")\n",
    "lsoa_centroids = lsoa_centroids[['LSOA11CD', 'cx', 'cy']].copy()\n",
    "lsoa_centroids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_map = pd.merge(london_map, lsoa_centroids, left_on='LSOA11CD', right_on='LSOA11CD', how = 'inner')\n",
    "london_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_geo = pd.merge(london_map, violent_crimes_new, left_on='LSOA11CD', right_on='lsoa_code', how = 'inner')\n",
    "violence_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_geo_1 = alt.InlineData(values = violence_geo.to_json(), #geopandas to geojson string\n",
    "                       format = alt.DataFormat(property='features',type='json'))\n",
    "\n",
    "alt.Chart(data_geo_1).mark_geoshape(strokeWidth=1,stroke='lightgray',strokeOpacity=0.2\n",
    ").encode(\n",
    "    color=alt.Color('properties.crime_per_1000_proportion:Q', scale = alt.Scale(scheme='reds')),\n",
    "    tooltip=['properties.lsoa_name:N', 'properties.crime_per_1000_proportion:Q', 'properties.police_total:Q']\n",
    ").properties(\n",
    "    projection={'type': 'identity','reflectY': True},\n",
    "    width=800,\n",
    "    height=450,\n",
    "    title='Serious Violent Crime by LSOA'\n",
    ").configure_axis(\n",
    "    grid=False,\n",
    "    domain=False\n",
    ").configure_view(\n",
    "    strokeWidth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a bubble plot in shape of London map, where bubbles are double encoded with color and \n",
    "# size to represent scale of crime\n",
    "yrange = (51.2, 51.8)\n",
    "\n",
    "alt.Chart(violence_geo, title='Serious Violent Crime by LSOA').mark_point(filled=True, opacity=0.9).encode(\n",
    "    x=alt.X('cx:Q', axis=None),\n",
    "    y=alt.Y('cy:Q', axis=None, scale=alt.Scale(domain=yrange)),\n",
    "    size='crime_per_1000',\n",
    "    color=alt.Color('crime_per_1000:Q', scale = alt.Scale(scheme='reds')),\n",
    "    tooltip=['lsoa_name:N', 'crime_per_1000_proportion:Q', 'police_total:Q']\n",
    ").configure_axis(\n",
    "    grid=False,\n",
    "    domain=False\n",
    ").configure_view(\n",
    "    strokeWidth=0).properties(\n",
    "    height=600, \n",
    "    width=600\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(violent_crimes_new.lsoa_code.count())\n",
    "\n",
    "highest_violent_crimes = violent_crimes_new.sort_values(by='crime_per_1000', ascending=False)[:50]\n",
    "\n",
    "all_sum = violent_crimes_new.crime_per_1000.sum()\n",
    "top_10_sum = violent_crimes_new.crime_per_1000.sort_values(ascending=False)[:10].sum()\n",
    "eleven_50_sum = violent_crimes_new.crime_per_1000.sort_values(ascending=False)[10:50].sum()\n",
    "fiftyone_250_sum = violent_crimes_new.crime_per_1000.sort_values(ascending=False)[50:250].sum()\n",
    "twofiftyone_1000_sum = violent_crimes_new.crime_per_1000.sort_values(ascending=False)[250:1000].sum()\n",
    "onethousand_2500_sum = violent_crimes_new.crime_per_1000.sort_values(ascending=False)[1000:2500].sum()\n",
    "twofiveOhone_end_sum = violent_crimes_new.crime_per_1000.sort_values(ascending=False)[2500:].sum()\n",
    "\n",
    "metrics = {\n",
    "    'metric' : ['1-10', '11-50', '51-250', '251-1000', '1001-2500', '2501-end'],\n",
    "    'value' : [top_10_sum, eleven_50_sum, fiftyone_250_sum, twofiftyone_1000_sum, onethousand_2500_sum, twofiveOhone_end_sum]\n",
    "}\n",
    "  \n",
    "# creating a Dataframe object from dictionary \n",
    "# with custom indexing\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df['percent'] = metrics_df.value / all_sum\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_6 = alt.Chart(highest_violent_crimes, title='Serious Violent Crime/1000, highest 50').mark_bar(opacity=0.6, color='firebrick').encode(\n",
    "    x=alt.X('crime_per_1000:Q', axis=alt.Axis(title='crimes per 1000', ticks=False, values=[0, 200, 400, 600, 800])),\n",
    "    y=alt.Y('lsoa_name:N', axis=alt.Axis(title=None, ticks=False), sort='-x')\n",
    ")\n",
    "\n",
    "text_6 = alt.Chart(highest_violent_crimes).mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    color='white',\n",
    "    dx=-15  # Nudges text to left so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    x=alt.X('crime_per_1000:Q', axis=alt.Axis(title='crimes per 1000', ticks=False)),\n",
    "    y=alt.Y('lsoa_name:N', axis=alt.Axis(title=None, ticks=False), sort='-x'),   \n",
    "    text=alt.Text('crime_per_1000:Q', format=',.3r')\n",
    ")\n",
    "\n",
    "(bars_6 + text_6).configure_axis(\n",
    "    grid=False,\n",
    "    domain=False\n",
    ").configure_view(\n",
    "    strokeWidth=0).properties(height=800, width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_7 = alt.Chart(metrics_df, title='Serious Violent Crime/1000: percentage of LSOA regions, by tranche').mark_bar(opacity=0.6, color='firebrick').encode(  \n",
    "    x=alt.X('metric:N', axis=alt.Axis(title='LSOAs, grouped in rankings from highest to lowest serious violent crime/1000', ticks=False, labelAngle=0), sort=['1-10', '11-50', '51-250', '251-1000', '1001-2500', '2501-end', 'All']),\n",
    "    y=alt.Y('percent:Q', axis=alt.Axis(title=None, ticks=False, format='%', values=[0, 0.1, 0.2, 0.3])),  \n",
    ")\n",
    "\n",
    "text_7 = alt.Chart(metrics_df).mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    color='white',\n",
    "    dy=8 \n",
    ").encode(\n",
    "    x=alt.X('metric:N', axis=None, sort=['1-10', '11-50', '51-250', '251-1000', '1001-2500', '2501-end', 'All']),\n",
    "    y=alt.Y('percent:Q', axis=None),  \n",
    "    text=alt.Text('percent:Q', format='.1%')\n",
    ")\n",
    "\n",
    "(bars_7 + text_7).configure_axis(\n",
    "    grid=False,\n",
    "    domain=False\n",
    ").configure_view(\n",
    "    strokeWidth=0).properties(height=600, width=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commentary on London wide context\n",
    "Notwithstanding the previously discussed reconciliation and data completeness concerns, we can make the following statements about Serious Violent Crime, excluding Sexual Offences:\n",
    "- London's nighttime and shopping economy is a magnet for violent crime because Westminster 18n encompasses Leicester Square, Covent Garden, Piccadilly Circus and through to Hyde Park, while Westminster 13n includes Oxford Street\n",
    "- The top 10 LSOAs suffer nearly 3% of the total serious violent crime rate across all 4,829 LSOAs\n",
    "- The top 250 LSOAs suffer around 19% of the total serious violent crime rate\n",
    "\n",
    "### Save file for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violent_crimes_new.to_csv('./DataSources/Crime and outcomes/violent_crimes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trends in serious violent crime between 2018 and 2019\n",
    "We have seen that the top 250 LSOAs experience nearly 19% of the serious violent crime rate in London. This suggests this is a cohort that deserves particular attention and it is also instructive to see whether the trends in crime rates are consistent across London or whether that also shows different patterns.\n",
    "\n",
    "To do this we load serious violent crime data from https://data.police.uk/data/ for the period ranging from May 2018 through to April 2020 to create a snapshot of two year's worth of data so that we can see how crime changed between 2018 and 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_trend_file = \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2018-05/2018-05-metropolitan-street.csv\"\n",
    "\n",
    "trend_files_18 = [\"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2018-06/2018-06-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2018-07/2018-07-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2018-08/2018-08-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2018-09/2018-09-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2018-10/2018-10-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2018-11/2018-11-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2018-12/2018-12-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2019-01/2019-01-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2019-02/2019-02-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2019-03/2019-03-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2019-04/2019-04-metropolitan-street.csv\"\n",
    "        ]\n",
    "\n",
    "trend_files_19 = [\"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2019-05/2019-05-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2019-06/2019-06-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2019-07/2019-07-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2019-08/2019-08-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2019-09/2019-09-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2019-10/2019-10-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2019-11/2019-11-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2019-12/2019-12-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2020-01/2020-01-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2020-02/2020-02-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2020-03/2020-03-metropolitan-street.csv\",\n",
    "        \"./DataSources/Crime and outcomes/CrimeAndOutcomes - 2018_19/2020-04/2020-04-metropolitan-street.csv\"\n",
    "        ]\n",
    "\n",
    "df_raw = pd.read_csv(first_trend_file)\n",
    "all_crime_trends = transform_df(df_raw, first_trend_file, '2018')\n",
    "\n",
    "print(all_crime_trends.shape)\n",
    "all_crime_trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_file in trend_files_18:\n",
    "    df_raw = pd.read_csv(this_file)\n",
    "    df = transform_df(df_raw, this_file, '2018')\n",
    "    all_crime_trends = pd.concat([all_crime_trends, df], axis=0)\n",
    "    \n",
    "print(all_crime_trends.shape)\n",
    "all_crime_trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_file in trend_files_19:\n",
    "    df_raw = pd.read_csv(this_file)\n",
    "    df = transform_df(df_raw, this_file, '2019')\n",
    "    all_crime_trends = pd.concat([all_crime_trends, df], axis=0)\n",
    "    \n",
    "print(all_crime_trends.shape)\n",
    "all_crime_trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violent_crime_trends_monthly = all_crime_trends[(all_crime_trends['Crime type'] == 'Violence and sexual offences') | \n",
    "                                 (all_crime_trends['Crime type'] == 'Robbery')].copy()\n",
    "\n",
    "print(violent_crime_trends_monthly.shape)\n",
    "violent_crime_trends_monthly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_data_trends_by_lsoa = violent_crime_trends_monthly.groupby([\"LSOA code\", \"year\"]).apply(lambda x: x['Month'].count()).reset_index()\n",
    "police_data_trends_by_lsoa.rename(columns = {0:'police_total'}, inplace = True)\n",
    "\n",
    "print(police_data_trends_by_lsoa.shape)\n",
    "police_data_trends_by_lsoa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip out non-London LSOAs\n",
    "This is to strip out noise from the Police Data (it contains some non London LSOAs) so get list of lsoa_codes from ldn_datastore. Then merge with population data so we can get crime per 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_lsoa_codes = ldn_datastore_by_lsoa.lsoa_code.unique()\n",
    "\n",
    "print(police_data_trends_by_lsoa.shape)\n",
    "police_data_trends_by_lsoa = police_data_trends_by_lsoa[police_data_trends_by_lsoa['LSOA code'].isin(london_lsoa_codes)].copy()\n",
    "\n",
    "print(police_data_trends_by_lsoa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with population data\n",
    "violent_crime_trends = pd.merge(police_data_trends_by_lsoa, population_data, left_on='LSOA code', right_on='LSOA Code', how = 'inner')\n",
    "violent_crime_trends.rename(columns = {'LSOA code':'lsoa_code'}, inplace = True)\n",
    "violent_crime_trends.rename(columns = {'LSOA Name':'lsoa_name'}, inplace = True)\n",
    "violent_crime_trends.rename(columns = {'All Ages':'population'}, inplace = True)\n",
    "\n",
    "violent_crime_trends['crime_per_1000'] = 1000 * violent_crime_trends.police_total / violent_crime_trends.population\n",
    "\n",
    "total_per_1000 = violent_crime_trends.crime_per_1000.sum()\n",
    "\n",
    "# multiply by 1000 so we don't have tiny numbers\n",
    "violent_crime_trends['crime_per_1000_proportion'] = 1000 * violent_crime_trends.crime_per_1000 / total_per_1000\n",
    "\n",
    "violent_crime_trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_rates_wide = violent_crime_trends.pivot_table(index=['lsoa_name'], \n",
    "                                    columns='year', values='crime_per_1000').reset_index()\n",
    "\n",
    "crime_rates_wide['pct_change'] = (crime_rates_wide['2019'] - crime_rates_wide['2018']) / crime_rates_wide['2018']\n",
    "\n",
    "crime_rates_wide['pct_change_abs'] = crime_rates_wide['pct_change'].abs()\n",
    "\n",
    "crime_rates_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only check for large changes within higher crime areas\n",
    "We limit the percent change analysis to areas with higher crime rates because otherwise we get silly results e.g. Bromley went from 1 instance of violent crime to 13 and that represents a 1300% increase, which is misleading in the context of chnages elsewhere. In addition, we check for the absolute change in crime rate because we want to see the largest changes irrespective of whether they are increases or decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_changes = crime_rates_wide[crime_rates_wide['2018'] > 25 ].sort_values(by='pct_change_abs', ascending=False)[:50]\n",
    "largest_changes.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_rates_wide['pct_change_abs'][crime_rates_wide['2018'] > 25 ].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_8 = alt.Chart(largest_changes, title='Largest increases or decreases in serious crime between 2018 and 2019 (where crime is greater than 25/1000)').mark_bar(opacity=0.6, color='firebrick').encode(\n",
    "    x=alt.X('pct_change:Q', axis=alt.Axis(title='% change', ticks=False, format='%', values=[-0.5, 0, 0.5, 1.0, 1.5, 2.0])),\n",
    "    y=alt.Y('lsoa_name:N', axis=alt.Axis(title=None, ticks=False), sort='-x')\n",
    ")\n",
    "\n",
    "text_8 = alt.Chart(largest_changes).mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    color='black',\n",
    "    dx=20  # Nudges text to right so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    x=alt.X('pct_change:Q', axis=alt.Axis(title='% change', ticks=False)),\n",
    "    y=alt.Y('lsoa_name:N', axis=alt.Axis(title=None, ticks=False), sort='-x'),\n",
    "    text=alt.Text('pct_change:Q', format='.0%')\n",
    ")\n",
    "\n",
    "vertline = alt.Chart().mark_rule(color='steelblue').encode(\n",
    "    x='a:Q'\n",
    ")\n",
    "\n",
    "alt.layer(\n",
    "    bars_8, text_8, vertline, \n",
    "    data=largest_changes\n",
    ").transform_calculate(\n",
    "    a=\"0.18\", b=\"50\"\n",
    ").configure_axis(\n",
    "    grid=False,\n",
    "    domain=False\n",
    ").configure_view(\n",
    "    strokeWidth=0).properties(height=600, width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments on changes in violent crime\n",
    "It should be noted that the changes in Knife Crime reported at Community Safety Partnership level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_changes_borough = pd.merge(violent_crime_trends, violent_crime_by_lsoa, how='inner', left_on='lsoa_code', right_on = 'lsoa_code')\n",
    "\n",
    "print(crime_changes_borough.shape)\n",
    "crime_changes_borough.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_changes_borough_new = crime_changes_borough[['lsoa_code', 'lsoa_name', 'borough', 'year', 'crime_per_1000']].copy()\n",
    "print(crime_changes_borough_new.shape)\n",
    "crime_changes_borough_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_changes_borough_wide = crime_changes_borough_new.pivot_table(index=['lsoa_name', 'borough'], \n",
    "                                    columns='year', values='crime_per_1000').reset_index()\n",
    "\n",
    "crime_changes_borough_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_changes_18_19 = crime_changes_borough_wide.groupby(['borough']).agg({'2018':'sum','2019':'sum'}).reset_index()\n",
    "print(borough_changes_18_19.shape)\n",
    "borough_changes_18_19.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_changes_18_19['pct_change'] = (borough_changes_18_19['2019'] - borough_changes_18_19['2018']) / borough_changes_18_19['2018']\n",
    "\n",
    "borough_changes_18_19['pct_change_abs'] = borough_changes_18_19['pct_change'].abs()\n",
    "\n",
    "borough_changes_18_19.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_9 = alt.Chart(borough_changes_18_19, title='Serious Violent Crime/1000 changes at borough level').mark_bar(opacity=0.6, color='firebrick').encode(\n",
    "    x=alt.X('pct_change_abs:Q', axis=alt.Axis(title='percent change', ticks=False, format='%', values=[0, 0.05, 0.1])),\n",
    "    y=alt.Y('borough:N', axis=alt.Axis(title=None, ticks=False), sort='-x')\n",
    ")\n",
    "\n",
    "text_9 = alt.Chart(borough_changes_18_19).mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    color='black',\n",
    "    dx=20  # Nudges text to left so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    x=alt.X('pct_change_abs:Q', axis=alt.Axis(title='percent change', ticks=False)),\n",
    "    y=alt.Y('borough:N', axis=alt.Axis(title=None, ticks=False), sort='-x'),   \n",
    "    text=alt.Text('pct_change_abs:Q', format='.1%')\n",
    ")\n",
    "\n",
    "(bars_9 + text_9).configure_axis(\n",
    "    grid=False,\n",
    "    domain=False\n",
    ").configure_view(\n",
    "    strokeWidth=0).properties(height=800, width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments on changes at Borough level\n",
    "We aggregated changes at Borough level to see how they compared with Knife crime data previously assessed at Community Safety Partnership level. It should be noted that this data reports changes for one year only and CSF data was for two years and also that there isn't a one to one mapping between borough and CSF, however, the results are quite different, which does question whether serious violent crime at aggregated level is actually a good a proxy for knife crime. THis will be discussed in the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Distribution\n",
    "Having analysed the data we now want to understand in more detail how it is distributed because we need a normally distributed dataset in order to perform our inferential statistics. We start by loading the file we have just saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_crimes = pd.read_csv(\"./DataSources/Crime and outcomes/violent_crimes.csv\")\n",
    "print(london_crimes.shape)\n",
    "london_crimes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.box(london_crimes, y=\"crime_per_1000\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers \n",
    "We know from our prior analysis that certain areas in London dominate the serious violent crime statistics and so it is no surprise to see the extent of these outliers within the box plot. We will now produce histograms and QQ plots for the entire distribution and also for a distribution created by selecting LSOAs whose crime_per_1000 falls between the upper and lower fences identified in the box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_middle_set = london_crimes[(london_crimes.crime_per_1000 < 62.1) & (london_crimes.crime_per_1000 > 1.35)].copy()\n",
    "\n",
    "print(\"Serious Violent Crime: Total count = {0:,}, while count where crime_per_1000 is between 1.35 and 62.1 = {1:,}\".format(london_crimes.crime_per_1000.count(), crime_middle_set.crime_per_1000.count()))\n",
    "\n",
    "f, axes = plt.subplots(2, 2, figsize=(16,8))\n",
    "f.suptitle('Histogram and QQ plot for whole and subset of serious violent crime distribution')\n",
    "sns.distplot(np.array(london_crimes.crime_per_1000), bins=50, ax=axes[0,0])\n",
    "axes[0,0].set_title('Histogram for full distribution')\n",
    "sm.qqplot(np.array(london_crimes.crime_per_1000), line='r', ax=axes[1,0])\n",
    "axes[1,0].set_title('QQ plot for full distribution')\n",
    "sns.distplot(np.array(crime_middle_set.crime_per_1000), bins=50, ax=axes[0,1])\n",
    "axes[0,1].set_title('Histogram: where crime_per_1000 is between 1.3 and 57.4')\n",
    "sm.qqplot(np.array(crime_middle_set.crime_per_1000), line='r', ax=axes[1,1])\n",
    "axes[1,1].set_title('QQ Plot: where crime_per_1000 is between 1.3 and 57.4')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments on distribution\n",
    "The Box plot and histogram confirm what we already knew, which is that the full distribution contains many outliers and these exist within the top 10, 50 and then 250 LSOAs. This creates a very right skewed distribution, with a very long tail. This would cause calculation issues with our inferential statistics because they assume normality in the distribution (well, the pearson correlation does while the spearman can cope better with outliers). However, if we bound our distribution to LSOAs where the crime_per_1000 is between 1.35 and 62.1 (which are the upper and lower fences in the boxplot), we remove the extreme outliers and the remaining distribution is more close to normal. Doing so only removes 252 of 4,829 observations (LSOAs), which is around 4.5% of our overall distribution. This will be our strategy for the inferential statistics.\n",
    "\n",
    "However, we will be using Random Forests as our classifier and this does not require a normal distribution. We will therefore keep the entire distribution when performing machine learning although we will remove the Westminster LSOAs from that analysis because they aren't residential areas and so not a representative region for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
